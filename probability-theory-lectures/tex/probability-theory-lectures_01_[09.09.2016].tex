\documentclass[a4paper,12pt]{article}
\usepackage{header}

\begin{document}

\maketitle

\section{Организационные моменты}
Формат отчётности:
\begin{enumerate}
    \item Две контрольных работы.
    \item Два коллоквиума.
    \item Домашние задания. В среднем на каждом семинаре будут выдавать по 2-3 задачи для самостоятельного решения, которые будет нужно сдавать ассистентам.
    \item Письменный экзамен --- ``расширенная КР''
\end{enumerate}

Итоговая оценка считается следующий образом:
\[O_{\text{итог}} = 0.3 \cdot O_{\text{экз}} + 0.1 \cdot O_{\text{ДЗ}} + 0.3 \cdot O_{\text{КР}} + 0.3 \cdot O_{\text{коллок}}\]

Округление оценки арифметическое.

На данный момент автоматов не предусмотрено.

\section{Лекция от 09.09.2016}

\subsection{Введение}
Чем занимается теория вероятностей? Она изучает \emph{случайные} явления. Допустим, мы провели какой-либо эксперимент. Можем ли мы что-то заранее сказать о результате?
\begin{itemize}
    \item Если да, то результат называют \emph{детерменированным}. Пример такого эксперимента --- выбрасывание кирпича из окна. Очевидно, что кирпич упадёт на землю\footnote{Если его не запустили с первой космической скоростью, конечно.} и результат предопределён. Такие задачи изучают в той же линейной алгебре или где-либо ещё, но не в теории вероятностей.
    \item А теперь предположим, что заранее сказать, каков будет результат, невозможно. Например, точно сказать, какой стороной упадёт подброшенная монетка, вряд ли получится. Тогда результат называют \emph{недетерменированным}. Именно задачи с недетерменированным результатом и изучаются в теории вероятностей.
\end{itemize}
Небольшое историческое отступление --- вообще говоря, теория вероятностей появилась в связи с изучением азартных игр наподобие рулетки ещё в средних веках. Но тогда она представляла собой скорее набор эмпирических фактов, чем полноценную науку. Теория вероятностей стала такой, какой она является сейчас, лишь в XX веке благодаря трудам А.Н. Колмогорова.

Хорошо, а как изучаются случайные процессы? Ну выпала решка, и что? На самом деле теория вероятностей не о единичных экспериментах, а об \emph{асимптотике}. Это значит следующее: если проводить серию одинаковых экспериментов, то теория вероятностей поможет предсказать частоту, с которой будет появляться какой-либо ответ.

Теория вероятностей держится на крайне важном \emph{принципе устойчивости частоты}. Перед тем, как ввести формальное определение, рассмотрим пару экспериментов, связанных с подбрасыванием монетки:
\begin{itemize}
    \item В XVIII веке Жорж-Луи Леклерк де Бюффон провёл эксперимент, подбросив монетку 4040 раз. Из них в 2048 бросках выпал герб. В итоге частота составила около 0.506.
    \item В XIX веке пошли ещё дальше --- Карл Пирсон подбросил монетку 24000 раз.\footnote{Оставим вопрос о том, как он не поленился провернуть это, без ответа.} У него получилось так, что герб выпал 12012 раз. В итоге частота составила 0.5005.
\end{itemize}
Отсюда видно, что эксперименты дают частоту, близкую к \(1/2\). 

Неформально говоря, принцип формулируется так: если мы проводим серию одинаковых экспериментов, то количество появлений одного определённого ответа при делении на число экспериментов сходится к некоторому числу \(p \in [0, 1]\). Теперь можно ввести формальное определение.
\begin{frequency-stability}
Пусть \(A\)~--- некоторое событие, а \(v_{n}(A)\)~--- число экспериментов, в которых происходит событие \(A\) среди первых \(n\). Тогда
\[\lim_{n \to \infty}\frac{v_{n}(A)}{n} = p,\quad p \in [0, 1] \]
\end{frequency-stability}
Получаемое число \(p\) называют \emph{вероятностью} события \(A\) и обозначают \(P(A)\). Например, \(P(\text{``встретить живого динозавра''}) = 0\), так как они все вымерли.

\subsection{Вероятностное пространство}

Именно после введения этого понятия Колмогоровым теория вероятностей перестала быть прежней. Введём определение для дискретного случая (общий оставим на потом):

\begin{definition}
\emph{Дискретным вероятностным пространством} называется пара \((\Omega, P)\), где \(\Omega\)~--- \emph{множество элементарных исходов}, а \(P\)~--- \emph{вероятность} на \(\Omega\).
\end{definition}

Множество элементарных исходов \(\Omega\)~--- некоторое конечное или счётное множество. Элемент \(\omega \in \Omega\) называют \emph{элементарным исходом}. Полагается, что в случайном эксперименте обязательно получается один и только один элементарный исход.

Примеры множеств элементарных исходов:

\begin{enumerate}
    \item \(\Omega = \left\{\text{О}, \text{Р}\right\}\)~--- бросок монеты.
    
    \item \(\Omega = \left\{\omega_1, \ldots, \omega_6\right\}\), где \(\omega_i\) = ``выпало \(i\) очков''~--- бросок игрального кубика.
    
    \item \(\Omega = \left\{\omega_1, \ldots, \omega_n, \ldots \right\}\), где \(\omega_i\) = ``на данный момент горит \(i\) зданий''~---  предсказание пожаров в городе.
\end{enumerate}

\begin{definition}
Подмножество \(A \subseteq \Omega\) называется \emph{событием} на вероятностном пространстве \((\Omega, P)\).
\end{definition}

Пример события: пусть подбрасывают игральную кость, и \(A\) = \(\{\)выпало чётное число очков\(\}\). Тогда \(A = \left\{\omega_2, \omega_4, \omega_6 \right\}\).

\begin{definition}
Отображение \(P : \Omega \to [0, 1]\) называют \emph{вероятностью}\footnote{В общем случае вероятность ещё могут называть \emph{вероятностной мерой}.}, если \[\sum_{\omega \in \Omega} P(\omega) = 1\]
В случае счётного множества \(\Omega\) данный ряд должен сходиться абсолютно.
\end{definition}

Пусть у нас есть некоторое событие \(A\) на вероятностном пространстве \((\Omega, P)\). Как посчитать его вероятность?

\begin{definition}
\emph{Вероятностью события} \(A \subseteq \Omega\) называют
\[P(A) = \sum_{\omega \in A} P(\omega)\]
\end{definition}

\begin{definition}
Пусть \(A\)~--- некое событие. Тогда \emph{дополнением} к событию \(A\) называют событие \(\overline{A} = \Omega \setminus A\).
\end{definition}

Перед тем, как идти дальше, напомню определение дизъюнктного объединения.
\begin{definition}
Пусть есть множества \(A_1, A_2, \ldots, A_n\). Тогда \emph{дизъюнктным объединением} множеств называют объединение попарно непересекающихся ``копий'' множеств: \[\bigsqcup_{i = 1}^{n} A_i = \bigcup_{i = 1}^{n} \left\{(x, i) \mid x \in A_i\right\}\] В нашем случае полагается, что если пишут дизъюнктное объединение, то множества попарно не пересекаются.
\end{definition}

Рассмотрим простейшие свойства вероятности.
\begin{lemma}
Для любого дискретного вероятностного пространства \((\Omega, P)\) выполняется следующее:
\begin{enumerate}
    \item \(P(\Omega) = 1\), \(P(\varnothing) = 0\).
    \item Конечная аддитивность: \[P\left(\bigsqcup_{i = 1}^{n} A_i\right) = \sum_{i = 1}^{n} P(A_i)\]
    \item \(P(A) + P(\overline{A}) = 1\).
    \item \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\).
    \item Для любого набора событий \(A_1, A_2, \ldots, A_n\) \[P\left(\bigcup_{i = 1}^{n} A_i\right) \leq \sum_{i = 1}^{n} P(A_i)\]
    \item Счётная аддитивность: \[P\left(\bigsqcup_{i = 1}^{\infty} A_i\right) = \sum_{i = 1}^{\infty} P(A_i)\]
\end{enumerate}
Последнее свойство выполняется только для счётного \(\Omega\).
\end{lemma}
\begin{proof}
Докажем каждый пункт леммы:
\begin{enumerate}
    \item \(P(\Omega) = 1\) следует из определения вероятности, а \(P(\varnothing) = 0\) следует из определения вероятности события.
    
    \item Случай с конечным множеством \(\Omega\) очевиден. Положим, что \(\Omega\) счётно, то есть \(\Omega = \left\{\omega_i \mid i \in \mathbb{N}\right\}\).
    
    Пусть есть некоторое событие \(A\). Тогда представим его вероятность в удобном для нас виде:
    \[P(A) = \sum_{\omega \in A} P(\omega) = \sum_{i\,:\,\omega_i \in A} P(\omega_i) = 
    \lim_{N \to \infty}\ \sum_{\mathclap{\substack{i\,:\, \omega_i \in A\\
    i < N}}} P(\omega_i)\]
    Теперь распишем вероятность дизъюнктного объединения событий \(A_1, A_2, \ldots, A_n\):
    \begin{multline*}
        P\left(\bigsqcup_{i = 1}^{n} A_i\right) = \sum_{\mathclap{\omega\,\in\,\bigsqcup A_i}} P(\omega) =
        \lim_{N \to \infty} \left(\sum_{\substack{i\,:\,\omega_i\,\in\,\bigsqcup A_i\\i < N}} P(\omega_i)\right) =
        \lim_{N \to \infty} \sum_{i = 1}^{n} \sum_{\substack{j\,:\,\omega_j\,\in\,A_i\\j < N}} P(\omega_j) = \\
        = \sum_{i = 1}^{n} \lim_{N \to \infty} \sum_{\substack{j\,:\,\omega_j\,\in\,A_i\\j < N}} P(\omega_j) = 
        \sum_{i = 1}^{n} P(A_i)
    \end{multline*}
    
    \item Согласно пункту 2, \(1 = P(\Omega) = P(A \cup \overline{A}) = P(A) + P(\overline{A})\).
    
    \item Так как \(A \cup B = A \cup (B \setminus A)\) и \(A \cap (B \setminus A) = \varnothing\), то \[P(A \cup B) = P(A) + P(B \setminus A)\]
    Заметим, что \(B \setminus A = B \setminus (A \cap B)\). Тогда
    \[P(A \cup B) = P(A) + P(B \setminus (A \cap B))\]
    Рассмотрим второй член. Заметим, что
    \[P(A \cap B) + P(B \setminus (A \cap B)) = P(B)\]
    Тогда получаем, что
    \[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]
    
    \item Докажем это утверждение по индукции. База была доказана в пункте 4 (так как \(P(A \cap B) \geq 0\)). Теперь рассмотрим шаг индукции. Пусть утверждение верно для какого-то \(m\). Тогда
    \[P\left(\bigcup_{i = 1}^{m + 1} A_i\right) \leq P(A_{m + 1}) + P\left(\bigcup_{i = 1}^{m} A_i\right) \leq \sum\limits_{i = 1}^{m + 1} P(A_i)\]
    
    \item За доказательством этого пункта обращайтесь к учебнику матанализа.\footnote{На самом деле я попробую найти доказательство. Когда-нибудь.}
\end{enumerate}
\end{proof}

\subsection{Классическая модель}
Пусть \((\Omega, P)\)~--- некоторое конечное вероятностное пространство, при этом все элементарные исходы равновероятны. Тогда легко посчитать вероятность элементарного исхода:
\[P(\omega) = \frac{1}{|\Omega|}\text{ для всех }\omega \in \Omega\]
Такую модель называют \emph{классической}.

Как посчитать вероятность события в классической модели? Очень просто:
\[P(A) = \frac{|A|}{|\Omega|}\text{ для всех }A \subseteq \Omega\]
Рассмотрим некоторые примеры классических моделей.
\begin{enumerate}
	\item Бросок монетки. В таком случае \(\Omega = \{\text{О}, \text{Р}\}\) и \(P(\text{О}) = P(\text{Р}) = \frac{1}{2}\).
	
	\item Бросок двух монеток. С этой моделью связано одно заблуждение Д'Аламбера. Он рассуждал следующим образом: так как \(\Omega = \{\text{ОО}, \text{РР}, \text{ОР}\}\), то \(P(\text{ОО}) = P(\text{РР}) = P(\text{ОР}) = \frac{1}{3}\). Но это опровергается экспериментами. И как это исправить? Есть два варианта:
	\begin{itemize}
		\item Можно сказать, что модель не является классической и поправить вероятности: \(P(\text{ОО}) = P(\text{РР}) = \frac{1}{4}\), \(P(\text{ОР}) = \frac{1}{2}\).
		\item А можно просто изменить множество элементарных исходов. Начнём учитывать порядок выпадения: \(\Omega = \{\text{ОО}, \text{РР}, \text{ОР}, \text{РО}\}\). Такая модель уже является классической.
	\end{itemize}
	Рассуждая в стиле Д'Аламбера, можно прийти к выводу, что вероятность встретить живого динозавра на улице равна \(\frac{1}{2}\), ведь его можно либо встретить, либо не встретить.
	
	\item Бросок \(n\) монет. В таком случае вероятностное пространство будет устроено следующим образом:
	\[\Omega = \left\{\omega = (\omega_1, \omega_2, \ldots, \omega_n) \mid \omega_i \in \left\{\text{О}, \text{Р}\right\}\right\}\]
	Легко понять, что в данной модели \(2^n\) элементарных исходов. Замечание: вероятностное пространство такого вида называют \emph{симметрической схемой Бернулли}.
	
	Но данная модель является классической только тогда, когда монетки ``честные'', то есть которые падают орлом или решкой вверх равновероятно. Если же это не так, то вероятность элементарного исхода \(\omega = (\omega_1, \omega_2, \ldots, \omega_n)\) задаётся следующей формулой:
	\[P(\omega) = p^{\,\sum\limits_{i = 1}^{n} \omega_i}(1 - p)^{n - \sum\limits_{i = 1}^{n} \omega_i}\]
	
	\item Урновые схемы (размещение частиц по ячейкам). Пусть есть \(n\) различных шаров в ящике. Мы случайным образом вынимаем \(m\) шаров. Вопрос: каков размер множества элементарных исходов? Сначала приведём ответ, после чего докажем его.
	
	\begin{center}
		\begin{tabular}{|c|c|c|} 
			\hline
			\diaghead{Порядоквозврат}{Возврат?}{Порядок?} & Упорядоченный набор & Неупорядоченный набор \\
			\hline
			&&\\[-10pt]
			С возвратом & \(n^{m}\) & \(C_{n + m - 1}^{m} = \dfrac{(n + m - 1)!}{m!(n - 1)!}\) \\[10pt]
			\hline
			&&\\[-10pt]
			Без возврата & \(A_{n}^{m} = \dfrac{n!}{(n - m)!}\) & \(C_{n}^{m} = \dfrac{n!}{m!(n - m)!}\) \\[10pt]
			\hline
		\end{tabular}
	\end{center}
	\begin{proof}
		\begin{enumerate}
			\item Пусть набор упорядочен и можно возвращать. Тогда любой элемент набора можно получить \(n\) способами (так как все элементы можно вернуть). Отсюда получаем \(n^m\).
			\item Теперь положим, что набор упорядочен, но возвращать нельзя. Тогда первый элемент можно выбрать \(n\) способами, второй~--- \(n - 1\) способом и так далее до \(m\)-го элемента, который можно выбрать \(n - m + 1\) способом. По правилу умножения получаем \(\frac{n!}{(n - m)!} = A_{n}^{m}\).
			\item Рассмотрим случай, когда набор неупорядочен и возвращать нельзя. Тогда необходимо посчитать количество способов выбрать \(k\) шаров из \(m\). Достаточно логично, что это равно \(\frac{A_{n}^{m}}{m!} = \frac{n!}{m!(n - m)!} = C_{n}^{m}\), так как в последовательности нам не важен порядок.
			\item Осталось рассмотреть последний случай~--- неупорядоченный набор с возвратом. В этом случае нам достаточно указать, сколько раз мы выбрали каждый шар. Как это сделать? Воспользуемся методом точек и перегородок. Пусть есть \(m\) точек и нужно распределить их по \(n\) группам. Для этого нужно использовать \(n - 1\) перегородку. Тогда задача сводится к нахождению количества способов выбрать \(m\) элементов из \(n + m - 1\). А это равно \(C_{n + m - 1}^{m} = \frac{(n + m - 1)!}{m!(n - 1)!}\).
		\end{enumerate}
	\end{proof}
\end{enumerate}

\subsection{Условная вероятность}
Пусть \((\Omega, P)\)~--- дискретное вероятностное пространство.
\begin{definition}
	Пусть \(A \subseteq \Omega\)~--- некоторое событие и \(B \subseteq \Omega\)~--- другое событие, причём \(P(B) > 0\). Тогда \emph{условной вероятностью события \(A\) при условии \(B\)} называют \[P(A \mid B) = \frac{P(A \cap B)}{P(B)}\]
	Если \(P(B) = 0\), то положим, что \(P(A \mid B) = 0\) для любого события \(A \subseteq \Omega\).
\end{definition}
Условную вероятность можно воспринимать следующим образом: сузим множество элементарных исходов до \(B\) и посчитаем вероятность события \(A\) на полученном множестве.
\begin{remark}
	Если \(P(B) > 0\), то \(\tilde{P}(A) = P(A \mid B)\) тоже является вероятностью на \(\Omega\).
\end{remark}
\begin{definition}
	Пусть \(B_1, B_2, \ldots, B_n\)~--- некоторые события на \(\Omega\) такие, что \(\bigsqcup\limits_{i = 1}^{n} B_i = \Omega\). Тогда этот набор событий называется (конечным) \emph{разбиением} \(\Omega\).
\end{definition}
Теперь докажем важную формулу:
\begin{law-of-total-probability}
	Пусть \(B_1, B_2, \ldots, B_n\)~--- разбиение \(\Omega\). Тогда для любого события \(A \subseteq \Omega\) верно, что \[P(A) = \sum\limits_{i = 1}^{n} P(A \mid B_i)P(B_i)\]
\end{law-of-total-probability}
\begin{proof}
	Так как \(A \cap \Omega = A\) и \(\bigsqcup\limits_{i = 1}^{n} B_i = \Omega\), то \(P(A) = P\left(A \cap \left(\bigsqcup\limits_{i = 1}^{n} B_i\right)\right)\). Заметим, что \(A \cap \left(\bigsqcup\limits_{i = 1}^{n} B_i\right) = \bigsqcup\limits_{i = 1}^{n} (A \cap B_i)\). Тогда
	\[P(A) = \sum_{i = 1}^{n} P(A \cap B_i) = \sum\limits_{i = 1}^{n} P(A \mid B_i)P(B_i)\]
\end{proof}
Заметим, что формула полной вероятности работает и в случае, когда \(P(B_i) = 0\) для какого-то \(i\).
\end{document}
